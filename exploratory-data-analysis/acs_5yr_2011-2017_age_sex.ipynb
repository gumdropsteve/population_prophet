{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default cleaning method until proven otherwise\n",
    "\n",
    "def clean_census_frame(csv_path , head=False , reset=True):\n",
    "    '''\n",
    "    inputs) \n",
    "        >> csv_path\n",
    "            > path to csv\n",
    "        >> head\n",
    "            > default=False\n",
    "                >> if != False\n",
    "                    > integer\n",
    "                        >> returns the first {head} rows (using .head() method) \n",
    "                            > instead of enitre dataframe\n",
    "        >> reset\n",
    "            > default=True\n",
    "                >> resets index after taking out rows\n",
    "            > if set to False\n",
    "                >> will not reset index\n",
    "    output)\n",
    "        >> dataframe cleaned like 2000 Census age&sex by 5-digit Zip Code (also how 2010 for same is cleaned)\n",
    "    how)\n",
    "        1. reads in csv , assumes it's large\n",
    "        2. makes a copy for editing \n",
    "            > and potential future use\n",
    "        3. locates readable column names  and non-readable names \n",
    "            > readable\n",
    "                    > e.g. Estimate; SEX AND AGE - Total population\n",
    "                >> assumes they are currently in row 0\n",
    "            > non-readable\n",
    "                    > e.g. HC01_VC03\n",
    "                >> assumes they are currently == dataframe.columns\n",
    "        4. replaces dataframe.columns (non-readable) with readable column names\n",
    "            > and drops the old 0th column (column where readable names were stored)\n",
    "        \n",
    "    '''\n",
    "    # load data\n",
    "    df = pd.read_csv( csv_path , low_memory=False )\n",
    "\n",
    "    # and copy\n",
    "    _df = df.copy()\n",
    "\n",
    "    # reset column names to current 0th row values\n",
    "    _df.columns = _df.iloc[0]\n",
    "    # new 2000 dataframe without row where values are from\n",
    "    clean_df = _df[1:]\n",
    "    \n",
    "    # default\n",
    "    if reset==True:\n",
    "        # reset index\n",
    "        clean_df = clean_df.reset_index()\n",
    "    \n",
    "    if head:\n",
    "        # return first {head} rows of dataframe\n",
    "        return clean_df.head(head)\n",
    "    else:\n",
    "        # return dataframe\n",
    "        return clean_df\n",
    "    \n",
    "    \n",
    "def show_lengths(collection):\n",
    "    '''\n",
    "    shows lengths of collection of items\n",
    "    '''\n",
    "    # collect\n",
    "    lengths = []\n",
    "    # iterate\n",
    "    for i in collection:\n",
    "        # add len to collect\n",
    "        lengths.append(len(i))\n",
    "    # return all lens\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv',low_memory=False)\n",
    "# ID=test.copy()\n",
    "# for _ in range(len(ID.columns)):\n",
    "#     for i in range(len(ID[ID.columns[_]])):\n",
    "#         if isinstance(ID[ID.columns[_]][i],str):\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(f'column {_}\\nrow {i}\\ntype {type(ID[ID.columns[_]][i])}\\n{ID[ID.columns[_]][i]}\\n\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***notes***:\n",
    "    - every instance is string (was no output)\n",
    "    - merged & hashed as to avoid running again on accident or restart^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload a year for base comps\n",
    "t000 = pd.read_csv('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv',low_memory=False)\n",
    "# limit size\n",
    "# test = test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t000.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_census_frame('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv',reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Id2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Estimate; SEX AND AGE - Total population</th>\n",
       "      <th>Margin of Error; SEX AND AGE - Total population</th>\n",
       "      <th>Percent; SEX AND AGE - Total population</th>\n",
       "      <th>Percent Margin of Error; SEX AND AGE - Total population</th>\n",
       "      <th>Estimate; SEX AND AGE - Total population - Male</th>\n",
       "      <th>Margin of Error; SEX AND AGE - Total population - Male</th>\n",
       "      <th>Percent; SEX AND AGE - Total population - Male</th>\n",
       "      <th>...</th>\n",
       "      <th>Percent; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races including Some other race</th>\n",
       "      <th>Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races including Some other race</th>\n",
       "      <th>Estimate; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races</th>\n",
       "      <th>Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races</th>\n",
       "      <th>Percent; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races</th>\n",
       "      <th>Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races</th>\n",
       "      <th>Estimate; HISPANIC OR LATINO AND RACE - Total housing units</th>\n",
       "      <th>Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units</th>\n",
       "      <th>Percent; HISPANIC OR LATINO AND RACE - Total housing units</th>\n",
       "      <th>Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>...</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "      <td>15446</td>\n",
       "      <td>2077</td>\n",
       "      <td>15446</td>\n",
       "      <td>1</td>\n",
       "      <td>11861</td>\n",
       "      <td>1439</td>\n",
       "      <td>698</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>567</td>\n",
       "      <td>1849</td>\n",
       "      <td>658</td>\n",
       "      <td>305</td>\n",
       "      <td>568</td>\n",
       "      <td>11145</td>\n",
       "      <td>692</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8600000US71647</td>\n",
       "      <td>84049</td>\n",
       "      <td>ZCTA5 49680</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>(X)</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>49.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>(X)</td>\n",
       "      <td>(X)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>134</td>\n",
       "      <td>306</td>\n",
       "      <td>33120</td>\n",
       "      <td>356</td>\n",
       "      <td>180</td>\n",
       "      <td>517</td>\n",
       "      <td>...</td>\n",
       "      <td>27022</td>\n",
       "      <td>5259</td>\n",
       "      <td>8028</td>\n",
       "      <td>3154</td>\n",
       "      <td>7809</td>\n",
       "      <td>1995</td>\n",
       "      <td>486</td>\n",
       "      <td>243</td>\n",
       "      <td>33120</td>\n",
       "      <td>33120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 327 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                   Id    Id2    Geography  \\\n",
       "count            33120  33120        33120   \n",
       "unique           33120  33120        33120   \n",
       "top     8600000US71647  84049  ZCTA5 49680   \n",
       "freq                 1      1            1   \n",
       "\n",
       "0      Estimate; SEX AND AGE - Total population  \\\n",
       "count                                     33120   \n",
       "unique                                    15446   \n",
       "top                                           0   \n",
       "freq                                        306   \n",
       "\n",
       "0      Margin of Error; SEX AND AGE - Total population  \\\n",
       "count                                            33120   \n",
       "unique                                            2077   \n",
       "top                                                 12   \n",
       "freq                                               134   \n",
       "\n",
       "0      Percent; SEX AND AGE - Total population  \\\n",
       "count                                    33120   \n",
       "unique                                   15446   \n",
       "top                                          0   \n",
       "freq                                       306   \n",
       "\n",
       "0      Percent Margin of Error; SEX AND AGE - Total population  \\\n",
       "count                                               33120        \n",
       "unique                                                  1        \n",
       "top                                                   (X)        \n",
       "freq                                                33120        \n",
       "\n",
       "0      Estimate; SEX AND AGE - Total population - Male  \\\n",
       "count                                            33120   \n",
       "unique                                           11861   \n",
       "top                                                  0   \n",
       "freq                                               356   \n",
       "\n",
       "0      Margin of Error; SEX AND AGE - Total population - Male  \\\n",
       "count                                               33120       \n",
       "unique                                               1439       \n",
       "top                                                    12       \n",
       "freq                                                  180       \n",
       "\n",
       "0      Percent; SEX AND AGE - Total population - Male  ...  \\\n",
       "count                                           33120  ...   \n",
       "unique                                            698  ...   \n",
       "top                                              49.4  ...   \n",
       "freq                                              517  ...   \n",
       "\n",
       "0      Percent; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races including Some other race  \\\n",
       "count                                               33120                                                                                           \n",
       "unique                                                 51                                                                                           \n",
       "top                                                   0.0                                                                                           \n",
       "freq                                                27022                                                                                           \n",
       "\n",
       "0      Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races including Some other race  \\\n",
       "count                                               33120                                                                                                           \n",
       "unique                                                567                                                                                                           \n",
       "top                                                   0.1                                                                                                           \n",
       "freq                                                 5259                                                                                                           \n",
       "\n",
       "0      Estimate; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races  \\\n",
       "count                                               33120                                                                                                                     \n",
       "unique                                               1849                                                                                                                     \n",
       "top                                                     0                                                                                                                     \n",
       "freq                                                 8028                                                                                                                     \n",
       "\n",
       "0      Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races  \\\n",
       "count                                               33120                                                                                                                            \n",
       "unique                                                658                                                                                                                            \n",
       "top                                                    11                                                                                                                            \n",
       "freq                                                 3154                                                                                                                            \n",
       "\n",
       "0      Percent; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races  \\\n",
       "count                                               33120                                                                                                                    \n",
       "unique                                                305                                                                                                                    \n",
       "top                                                   0.0                                                                                                                    \n",
       "freq                                                 7809                                                                                                                    \n",
       "\n",
       "0      Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races  \\\n",
       "count                                               33120                                                                                                                                    \n",
       "unique                                                568                                                                                                                                    \n",
       "top                                                   0.7                                                                                                                                    \n",
       "freq                                                 1995                                                                                                                                    \n",
       "\n",
       "0      Estimate; HISPANIC OR LATINO AND RACE - Total housing units  \\\n",
       "count                                               33120            \n",
       "unique                                              11145            \n",
       "top                                                     0            \n",
       "freq                                                  486            \n",
       "\n",
       "0      Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units  \\\n",
       "count                                               33120                   \n",
       "unique                                                692                   \n",
       "top                                                    12                   \n",
       "freq                                                  243                   \n",
       "\n",
       "0      Percent; HISPANIC OR LATINO AND RACE - Total housing units  \\\n",
       "count                                               33120           \n",
       "unique                                                  1           \n",
       "top                                                   (X)           \n",
       "freq                                                33120           \n",
       "\n",
       "0      Percent Margin of Error; HISPANIC OR LATINO AND RACE - Total housing units  \n",
       "count                                               33120                          \n",
       "unique                                                  1                          \n",
       "top                                                   (X)                          \n",
       "freq                                                33120                          \n",
       "\n",
       "[4 rows x 327 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33120"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ID[col_names[_]]) \n",
    "# ID[col_names[_]][33120] == ID[col_names[_]][33120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many columns have instances only containing '+-0123456789.'\n",
    "# copy\n",
    "ID=test.copy()\n",
    "\n",
    "# start out log\n",
    "out = []\n",
    "\n",
    "# pull names\n",
    "col_names = ID.columns\n",
    "\n",
    "# id target \n",
    "indicates_num = '1234567890-=. '\n",
    "\n",
    "# index (0-327)\n",
    "idx = [len(ID[col_names[_]]) for _ in range(len(col_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2241c6f02aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdinks_on_armor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# set instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# weak armor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2938\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2940\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[0;32m-> 1231\u001b[0;31m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[1;32m   1232\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[1;32m   1311\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                               fill_tuple=None))\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1234\u001b[0;31m                                        allow_fill=False, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# index columns\n",
    "for _ in range(len(col_names)):\n",
    "    print(f'START {_}')\n",
    "    # hits to perfect column \n",
    "    total_dinks = 0\n",
    "    # column summary \n",
    "    column_sum = []\n",
    "\n",
    "    # for length of column in dataframe\n",
    "    for i in range(1,idx[_]):\n",
    "        # assume column is good\n",
    "        dinks_on_armor = 0\n",
    "        # set instance\n",
    "        inst = ID[col_names[_]][i]\n",
    "\n",
    "        # weak armor\n",
    "        if dinks_on_armor == 0:\n",
    "            # if that instance is a string\n",
    "            # expected True via prior research \n",
    "            if isinstance(inst,str):\n",
    "\n",
    "                # start evaluation count on if it can be made a number\n",
    "                better = 0\n",
    "                # take each character in that string\n",
    "                for c in inst:\n",
    "                    # assume that character is an indicator (good) (expected more frequently than not)\n",
    "                    good = 0\n",
    "\n",
    "                    # check that character is indicator\n",
    "                    if c not in indicates_num:\n",
    "                        # if not, flip switch\n",
    "                        good+=1\n",
    "                        # and document\n",
    "                        # print(f'ID.columns[_] = {col_names[_]}\\nID[ID.columns[_]][i] = {ID[col_names[_]][i]}\\nc = {c}\\n')\n",
    "\n",
    "                    # if we're still good\n",
    "                    if good == 0:\n",
    "                        # do better\n",
    "                        better += 1\n",
    "                # at least 1 character was not in target, indicates object may have issue converting to num type\n",
    "                if better != len(c):\n",
    "                    # add\n",
    "                    dinks_on_armor += 1 \n",
    "                    # note\n",
    "                    column_sum.append([i,inst])\n",
    "\n",
    "            # expected to occour 0 times\n",
    "            else:\n",
    "                # alert \n",
    "                print(f'column {_}\\nrow {i}\\ntype {type(ID[col_names[_]][i])}\\n{ID[col_names[_]][i]}\\n\\n') \n",
    "                # document\n",
    "                sus_instance_info.append(f'column {_}\\nrow {i}\\ntype {type(ID[col_names[_]][i])}\\n{ID[col_names[_]][i]}\\n\\n')\n",
    "\n",
    "        # update column summary \n",
    "        column_sum.append([i,ID[col_names[_]],dinks_on_armor])\n",
    "        # add the dinks\n",
    "        total_dinks += dinks_on_armor\n",
    "    \n",
    "    # add the column number, column name column summary, and total dinks on armor\n",
    "    out.append([_,col_names[_],column_sum,total_dinks])\n",
    "    print(f'{_}/{len(col_names)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=0\n",
    "for i in [i for i in range(10)]:\n",
    "    if not isinstance(i,int):\n",
    "        print(i)\n",
    "    else:\n",
    "        q+=1\n",
    "q, len([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload a year for base comps\n",
    "# test = pd.read_csv('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv',low_memory=False)\n",
    "# # limit size\n",
    "# # test = test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in test.HC01_VC03:\n",
    "    if isinstance(t,str):\n",
    "        pass\n",
    "    else:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm location of column names and current column names\n",
    "test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine metadata (2014 is same as 2011-2013 as same len(.columns))\n",
    "meta_fourteen_ =  pd.read_csv('../data/acs/aff_download/ACS_14_5YR_DP05_metadata.csv')\n",
    "for _ in range(1,len(meta_fourteen_)):\n",
    "    print(str(meta_fourteen_.Id[_-1:_])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***notes***:\n",
    "    - looks nothing like the online American Fact Finder version \n",
    "        - always fun\n",
    "    - online 2014\n",
    "        - highest columns are Geography\n",
    "            - ZCTA5 00601\n",
    "            - which is broken into subcolumns\n",
    "                - Total, Male, Female\n",
    "                - each of which are broken into subcolumns\n",
    "                    - Estimate, Margin of Error\n",
    "        - effectively\n",
    "            - each Geography is represented by 6 columns\n",
    "        - seems I have more information regarding race and ethnicity per zip\n",
    "- ***actions***:\n",
    "    - represent each area by Geography in each table\n",
    "    - compare evolution of that Geography\n",
    "        - Clustering (KNN)\n",
    "        - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2011\n",
    "y2k11 = clean_census_frame('../data/acs/aff_download/ACS_11_5YR_DP05_with_ann.csv')\n",
    "# 2012\n",
    "y2k12 = clean_census_frame('../data/acs/aff_download/ACS_12_5YR_DP05_with_ann.csv')\n",
    "#2013\n",
    "y2k13 = clean_census_frame('../data/acs/aff_download/ACS_13_5YR_DP05_with_ann.csv')\n",
    "# 2014\n",
    "y2k14 = clean_census_frame('../data/acs/aff_download/ACS_14_5YR_DP05_with_ann.csv')\n",
    "# 2015\n",
    "y2k15 = clean_census_frame('../data/acs/aff_download/ACS_15_5YR_DP05_with_ann.csv')\n",
    "# 2016\n",
    "y2k16 = clean_census_frame('../data/acs/aff_download/ACS_16_5YR_DP05_with_ann.csv')\n",
    "# 2017\n",
    "y2k17 = clean_census_frame('../data/acs/aff_download/ACS_17_5YR_DP05_with_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it's always come with such joy, let's check length\n",
    "full_yrs = [y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17]\n",
    "# we want these to all be the same\n",
    "show_lengths(full_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2k14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MAKE IT FASTER >> done to speed up modeling process'''\n",
    "\n",
    "# 2011\n",
    "sy2k11 = y2k11.head(1000)\n",
    "# 2012\n",
    "sy2k12 = y2k12.head(1000)\n",
    "#2013\n",
    "sy2k13 = y2k13.head(1000)\n",
    "# 2014\n",
    "sy2k14 = y2k14.head(1000)\n",
    "# 2015\n",
    "sy2k15 = y2k15.head(1000)\n",
    "# 2016\n",
    "sy2k16 = y2k16.head(1000)\n",
    "# 2017\n",
    "sy2k17 = y2k17.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy2k14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather column names\n",
    "column_names = [_ for _ in sy2k11[:0]]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in [sy2k11,sy2k12,sy2k13,sy2k14,sy2k15,sy2k16,sy2k17]:\n",
    "    print(_.info(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy2k14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine columns in 2015, 2016 and 2017 which are not seen in 2011-2014 \n",
    "eleven_columns = [name for name in sy2k11.columns]\n",
    "twelve_columns = [name for name in sy2k12.columns]\n",
    "thirteen_columns = [name for name in sy2k12.columns]\n",
    "fourteen_columns = [name for name in sy2k12.columns]\n",
    "fifteen_columns = [name for name in sy2k15.columns]\n",
    "sixteen_columns = [name for name in sy2k16.columns]\n",
    "seventeen_columns = [name for name in sy2k17.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare lengths of columns\n",
    "show_lengths([eleven_columns,twelve_columns,thirteen_columns,fourteen_columns,fifteen_columns,sixteen_columns,seventeen_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make sure those with 328 columns all have the same columns'''\n",
    "\n",
    "# collect similar\n",
    "w_328_cols = [eleven_columns,twelve_columns,thirteen_columns,fourteen_columns]\n",
    "\n",
    "# count non coexist \n",
    "same_len_non_coexist = 0\n",
    "\n",
    "# show lens\n",
    "show_w_328 = show_lengths(w_328_cols)\n",
    "# double check lengths\n",
    "for i in range(len(show_w_328)):\n",
    "    if show_w_328[i] != show_w_328[-i]:\n",
    "        raise Exception(f'ERROR len != len\\n{show_w_328[i]} != {show_w_328[-i]}')\n",
    "\n",
    "# compare all to initial \n",
    "for name in eleven_columns: \n",
    "    if name not in twelve_columns:\n",
    "        same_len_non_coexist+=1\n",
    "        # raise Exception(f'FLAWED ASSUMPTION if name in y2k12.columns name = {name}')\n",
    "    elif name not in thirteen_columns:\n",
    "        same_len_non_coexist+=1\n",
    "        #raise Exception(f'FLAWED ASSUMPTION if name in y2k13.columns name = {name}')\n",
    "    elif name not in fourteen_columns:\n",
    "        same_len_non_coexist+=1\n",
    "        #raise Exception(f'FLAWED ASSUMPTION if name in y2k14.columns name = {name}')\n",
    "\n",
    "# final hurdle, check for non coexisting (based on prior hoops this should be a given)\n",
    "if same_len_non_coexist > 0:\n",
    "    raise Exception(f'FLAWED ASSUMPTION same_len_non_coexist ({same_len_non_coexist}) > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make sure those with 340 columns all have the same columns'''\n",
    "\n",
    "for _ in range(len(fifteen_columns)): \n",
    "    if fifteen_columns[_] != sixteen_columns[_]:\n",
    "        raise Exception(f'FLAWED ASSUMPTION if name in y2k12.columns name = {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''see if those 328 column names are seen in 2015, 2016, and 2017'''\n",
    "# store non coexist 2011 vs 2015\n",
    "non_coexist_2015 = []\n",
    "# store non coexist 2011 vs 2016\n",
    "non_coexist_2016 = []\n",
    "# store non coexist 2011 vs 2017\n",
    "non_coexist_2017 = []\n",
    "\n",
    "# compare to initial \n",
    "for _ in range(len(eleven_columns)): \n",
    "    # 2017\n",
    "    if eleven_columns[_] not in seventeen_columns:\n",
    "        # update 2017 bag w/ index & instance\n",
    "        non_coexist_2017.append((_,eleven_columns[_]))\n",
    "    # 2016\n",
    "    if eleven_columns[_] not in sixteen_columns:\n",
    "        # update 2016 bag w/ index & instance\n",
    "        non_coexist_2016.append((_,eleven_columns[_]))\n",
    "    # 2015\n",
    "    if eleven_columns[_] not in fifteen_columns:\n",
    "        # update 2015 bag w/ index & instance\n",
    "        non_coexist_2015.append((_,eleven_columns[_]))\n",
    "\n",
    "\n",
    "'''reverse vs 2016 and then vs 2017 if 2015 == 2016'''\n",
    "if fifteen_columns == sixteen_columns:\n",
    "    \n",
    "    # store non coexist 2016 vs 2011\n",
    "    _from_2016_non_coexist_2011 = []\n",
    "    # store non coexist 2017 vs 2011\n",
    "    _from_2017_non_coexist_2011 = []\n",
    "    \n",
    "    # 2017\n",
    "    for _ in range(len(seventeen_columns)):\n",
    "        if seventeen_columns[_] not in eleven_columns:\n",
    "            # update 2017 bag w/ index & instance\n",
    "            _from_2017_non_coexist_2011.append((_,seventeen_columns[_]))\n",
    "    # 2016\n",
    "    for _ in range(len(sixteen_columns)):\n",
    "        if sixteen_columns[_] not in eleven_columns:\n",
    "            # update 2016 bag w/ index & instance\n",
    "            _from_2016_non_coexist_2011.append((_,sixteen_columns[_]))\n",
    "    \n",
    "# let us know if 2015 != 2016\n",
    "else:\n",
    "    raise Exception('ERROR\\nfifteen_columns != sixteen_columns\\nERROR')\n",
    "\n",
    "    \n",
    "'''2016 vs 2017 and reverse'''\n",
    "# store non coexist 2016 vs 2017\n",
    "_from_2016_non_coexist_2017 = []\n",
    "# store non coexist 2017 vs 2016\n",
    "_from_2017_non_coexist_2016 = []\n",
    "\n",
    "# from 2017 to 2016\n",
    "for _ in range(len(seventeen_columns)):\n",
    "    if seventeen_columns[_] not in eleven_columns:\n",
    "        # update 2017 bag w/ index & instance\n",
    "        _from_2017_non_coexist_2016.append((_,seventeen_columns[_]))\n",
    "# from 2016 to 2017\n",
    "for _ in range(len(sixteen_columns)):\n",
    "    if sixteen_columns[_] not in seventeen_columns:\n",
    "        # update 2016 bag w/ index & instance\n",
    "        _from_2016_non_coexist_2017.append((_,sixteen_columns[_]))\n",
    "    \n",
    "'''2011 vs 2015/2016/2017'''\n",
    "# count non coexist 2011 vs 2015\n",
    "non_coexist_2015_count = len(non_coexist_2015)\n",
    "# count non coexist 2011 vs 2016\n",
    "non_coexist_2016_count = len(non_coexist_2016)\n",
    "# count non coexist 2011 vs 2017\n",
    "non_coexist_2017_count = len(non_coexist_2017)\n",
    "# count non coexist 2011 vs each in ALL\n",
    "non_coexist_count = non_coexist_2015_count + non_coexist_2016_count + non_coexist_2017_count\n",
    "# identify unique non coexistances\n",
    "u_non_coexist = set(non_coexist_2015 + non_coexist_2016 + non_coexist_2017)\n",
    "# count the number of unique non coexist 2011 vs each in All\n",
    "u_non_coexist_count = len(u_non_coexist)\n",
    "\n",
    "'''2016/2017 vs 2011'''\n",
    "# count non coexist 2016 vs 2011\n",
    "_from_2016_non_coexist_2011_count = len(_from_2016_non_coexist_2011)\n",
    "# count non coexist 2017 vs 2011\n",
    "_from_2017_non_coexist_2011_count = len(_from_2017_non_coexist_2011)\n",
    "# identify unique non coexistances (exist in 2016 or 2017 but not in 2011)\n",
    "r_u_non_coexist = set(_from_2016_non_coexist_2011 + _from_2017_non_coexist_2011)\n",
    "# count the number of unique non coexist 2011 vs each in All\n",
    "r_u_non_coexist_count = len(r_u_non_coexist)\n",
    "\n",
    "'''2016 & 2017'''\n",
    "# count non coexist 2016 vs 2017\n",
    "_from_2016_non_coexist_2017_count = len(_from_2016_non_coexist_2017)\n",
    "# count non coexist 2017 vs 2016\n",
    "_from_2017_non_coexist_2016_count = len(_from_2017_non_coexist_2016)\n",
    "\n",
    "# 2011 vs\n",
    "print(f'forward\\n2011 vs 2015\\nnon_coexist_2015_count = {non_coexist_2015_count} /{len(fifteen_columns)}\\n'\n",
    "        f'2011 vs 2016\\nnon_coexist_2016_count = {non_coexist_2016_count} /{len(sixteen_columns)}\\n'\n",
    "        f'2011 vs 2017\\nnon_coexist_2017_count = {non_coexist_2017_count} /{len(seventeen_columns)}\\n'\n",
    "        f'2011 vs all\\ninstances not existing in all  = {u_non_coexist_count} / {len(eleven_columns)} possible\\n')\n",
    "# vs 2011\n",
    "print(f'backward\\n2016 vs 2011\\n_from_2016_non_coexist_2011_count = {_from_2016_non_coexist_2011_count} /{len(sixteen_columns)}\\n'\n",
    "        f'2017 vs 2011\\n_from_2017_non_coexist_2011_count = {_from_2017_non_coexist_2011_count} /{len(sixteen_columns)}\\n'\n",
    "        f'ALL vs 2011\\nunique non coexist 2011 vs each in All = {r_u_non_coexist_count}\\n')\n",
    "# 2016/2017 & 2017/2016\n",
    "print(f'2016 & 2016\\n2016 vs 2017\\n_from_2016_non_coexist_2017_count = {_from_2016_non_coexist_2017_count} /{len(sixteen_columns)}\\n'\n",
    "        f'2017 vs 2016\\n_from_2017_non_coexist_2016_count = {_from_2017_non_coexist_2016_count} /{len(seventeen_columns)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some\n",
    "u_non_coexist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***notes***:\n",
    "    - 108 columns (distinctions) of 328\n",
    "- ***possible***:\n",
    "    - take out non-coexisting columns from all dataframes\n",
    "        - then compare\n",
    "            - would result in loss of ~1/3+ of columns\n",
    "    - try to adjust\n",
    "        - find what would be\n",
    "            - seems possible for columns like the following\n",
    "                - 10, 'Percent; SEX AND AGE - Male'\n",
    "                - 96, 'Estimate; SEX AND AGE - Female'\n",
    "                - 248, 'Estimate; RACE - Asian'\n",
    "            - but more difficult for columns like\n",
    "                - 11, 'Percent Margin of Error; SEX AND AGE - Male'\n",
    "                - 97, 'Margin of Error; SEX AND AGE - Female'\n",
    "                - 323, 'Percent Margin of Error; HISPANIC OR LATINO AND RACE - Not Hispanic or Latino - Two or more races - Two races excluding Some other race, and Three or more races')\n",
    "                    - though ?could exclue this when calculating change?\n",
    "        \n",
    "- ***actions***:\n",
    "    - time is becoming a more relevant an issue, MVP due today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for each zip code, should contain row from each year\n",
    "def frame_per_zip(dataframes):\n",
    "    '''\n",
    "    take dataframe for each year set is available\n",
    "    find common zipcode for each year\n",
    "    make dataframe for that zipcode\n",
    "        containing each year's measurements\n",
    "    note:\n",
    "        dataframes must be same length\n",
    "    '''\n",
    "    # check length of dataframes is same\n",
    "    for _ in range(len(dataframes)):\n",
    "        # done to ensure each zip code has same represnetation \n",
    "        if len(dataframes[_-1]) != len(dataframes[_]):\n",
    "            # stop if we have different lengths\n",
    "            raise Exception(f'len(dataframe[{-_}]) != len(dataframe[{_}])')\n",
    "        # also check that dataframes have same Id\n",
    "        random_samples = [random.randint(1,int(len(dataframes[-_])/2)),\n",
    "                          random.randint(1,int(len(dataframes[-_]))),\n",
    "                          random.randint(int(len(dataframes[-_])/2),len(dataframes[-_]))]\n",
    "        for sample in random_samples:\n",
    "            # pull Id from df to compare\n",
    "            if dataframes[_]['Id'][sample] != dataframes[_-2]['Id'][sample]:\n",
    "                # stop if they don't match\n",
    "                raise Exception(f\"NON MATCHING Id\\n{dataframes[_].Id[sample]}\\nERROR\\n{dataframes[_-2].Id[sample]}\\n\")\n",
    "    \n",
    "    # now we can get to work\n",
    "    mini_dfs = []\n",
    "    for i in range(len(dataframes[0])):\n",
    "        mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=dataframes[0].columns)\n",
    "        for _ in range(len(dataframes)):\n",
    "            q = dataframes[_]\n",
    "            print(q)\n",
    "#             mini_df[_] = q.index(i)\n",
    "        mini_dfs.append(mini_df)\n",
    "    \n",
    "    print(len(mini_df))\n",
    "        \n",
    "    return mini_dfs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs = [sy2k11,sy2k12,sy2k13,sy2k14,sy2k15,sy2k16,sy2k17]\n",
    "# z = frame_per_zip(yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in yrs:\n",
    "    print (year.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=['a','b','c','d','e'])\n",
    "mini_df[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = [y2k11,y2k12,y2k13,y2k14,y2k15,y2k16,y2k17]\n",
    "# mini_df = pd.DataFrame(index=['2011','2012','2013','2014','2015','2016','2017'], columns=dataframes[0].columns)\n",
    "# mini_df.iloc[0] = 'lol'\n",
    "# mini_df.iloc[0]\n",
    "# mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# load 2000 data\n",
    "y2k = pd.read_csv( a , low_memory=False )\n",
    "# load 2010 data\n",
    "y2k10 = pd.read_csv( b , low_memory=False )\n",
    "\n",
    "# 2000 Census\n",
    "b = y2k.copy()\n",
    "# 2010 Census\n",
    "o = y2k10.copy()\n",
    "\n",
    "# reset 2000 columns to current 0th row values\n",
    "b.columns = b.iloc[0]\n",
    "# new 2000 dataframe without row where values are from\n",
    "b = b[1:]\n",
    "# reset index\n",
    "b = b.reset_index()\n",
    "\n",
    "# reset 2010 columns to current 0th row values\n",
    "o.columns = o.iloc[0]\n",
    "# new 2010 dataframe without row where values are from\n",
    "o = o[1:]\n",
    "# reset index\n",
    "o = o.reset_index()\n",
    "\n",
    "# identify zip codes from 2000 .Geography (last 5 chars of string)\n",
    "zip_2000_codes = [q[-5:] for q in b.Geography]  # ValueError: invalid literal for int() with base 10: '006HH'\n",
    "# identify zip codes from 2010 .Geography (last 5 chars of string)\n",
    "zip_2010_codes = [q[-5:] for q in o.Geography]\n",
    "\n",
    "# from 2000.Geography , instance is not seen in 2010.Geography  -- sample: zip_code = (2, 'c')\n",
    "in_2000_but_not_2010_from_2000 = [zip_code for zip_code in enumerate(zip_2000_codes) if zip_code[1] not in zip_2010_codes]\n",
    "# from 2010.Geography , instance is not seen in 2000.Geography  -- sample: zip_code[1] = 'c'\n",
    "in_2010_but_not_2000_from_2010 = [zip_code for zip_code in enumerate(zip_2010_codes) if zip_code[1] not in zip_2000_codes]\n",
    "\n",
    "# from 2000.Geography , instance is seen in 2010.Geography\n",
    "in_2000_and_2010_from_2000 = [zip_code for zip_code in enumerate(zip_2000_codes) if zip_code[1] in zip_2010_codes]\n",
    "# from 2010.Geography , instance is seen in 2000.Geography\n",
    "in_2010_and_2000_from_2010 = [zip_code for zip_code in enumerate(zip_2010_codes) if zip_code[1] in zip_2000_codes]\n",
    "\n",
    "# index of objects coexisting in 2000 and 2010\n",
    "of_2000_indexes = [i for i,j in in_2000_and_2010_from_2000]\n",
    "# index of objects coexisting in 2010 and 2000 \n",
    "of_2010_indexes = [i for i,j in in_2010_and_2000_from_2010]\n",
    "# ^note: these are different lists, if took j instead of i, then would be same list\n",
    "if [j for i,j in in_2000_and_2010_from_2000] != [j for i,j in in_2010_and_2000_from_2010]:\n",
    "    # like is seen here, j for j == True\n",
    "    raise Exception(f'FLAWED ASSUMPTION , [j for i,j in 2000] != [j for i,j in 2010]\\n'\n",
    "                    f'len {len(in_2000_and_2010_from_2000)} {len(in_2010_and_2000_from_2010)}')\n",
    "# however i for i == False\n",
    "if of_2000_indexes == of_2010_indexes:\n",
    "    # cheers\n",
    "    raise Exception('FLAWED ASSUMPTION , of_2000_indexes != of_2010_indexes\\n'\n",
    "                    f'len y2k {len(of_2000_indexes)} 2k10 {len(of_2010_indexes)}')  \n",
    "\n",
    "# thin 2000 to shared geo\n",
    "b = b.iloc[of_2000_indexes]\n",
    "# thin 2010 to shared geo\n",
    "o = o.iloc[of_2010_indexes]'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"play df\"\"\"\n",
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42], 'Weight':[128,134,129,142]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"play list\"\"\"\n",
    "a = [1,2,3,3,5,69,1,2,7,9,2]\n",
    "b = [1,2,3]\n",
    "c = [10,20,50,69]\n",
    "d = set(a+b+c)\n",
    "# d = set(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(y2k11.set_index('Geography'),  figsize=(10, 10), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy2k11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z=0\n",
      "x=1\n",
      "z=0\n",
      "x=2\n",
      "z=0\n",
      "x=3\n",
      "z=1\n",
      "x=4\n",
      "z=1\n",
      "x=5\n",
      "z=1\n",
      "x=6\n",
      "z=1\n",
      "x=7\n",
      "z=1\n",
      "x=2\n",
      "z=1\n",
      "x=6\n",
      "z=1\n",
      "x=1\n",
      "z=1\n",
      "x=9\n",
      "z=1\n",
      "x=1\n",
      "z=1\n",
      "x=4\n",
      "z=1\n",
      "x=1\n"
     ]
    }
   ],
   "source": [
    "q = [1,2,3,'4',5,6,7,2,6,1,9,1,4,1]\n",
    "z = 0\n",
    "while z ==0:\n",
    "    for x in q:\n",
    "        if isinstance(x,str):\n",
    "            z+=1\n",
    "        print(f'z={z}\\nx={x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
